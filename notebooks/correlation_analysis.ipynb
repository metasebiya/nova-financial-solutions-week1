{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308a33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.getcwd()  # Get current working directory (notebooks folder)\n",
    "project_dir = os.path.abspath(os.path.join(notebook_dir, '..'))  # Go up one level\n",
    "src_dir = os.path.join(project_dir, 'src')  # Path to scripts\n",
    "scripts_dir = os.path.join(project_dir, 'scripts')\n",
    "sys.path.append(src_dir)\n",
    "sys.path.append(scripts_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a264f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Analyzer' from 'pynance' (c:\\Users\\hp\\Documents\\10\\nova-financial-solutions-week1\\.venv\\Lib\\site-packages\\pynance\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisualize_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Visualizer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcorrelation_analyzer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CorrelationAnalyzer\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfinancial_analyzer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FinancialAnalyzer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\Documents\\10\\nova-financial-solutions-week1\\scripts\\financial_analyzer.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtalib\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpynance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpynance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Analyzer\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFinancialAnalyzer\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataframe):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Analyzer' from 'pynance' (c:\\Users\\hp\\Documents\\10\\nova-financial-solutions-week1\\.venv\\Lib\\site-packages\\pynance\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from load_data import DataLoader\n",
    "from clean_data import DataCleaner\n",
    "from visualize_data import Visualizer\n",
    "from load_data import DataLoader\n",
    "from clean_data import DataCleaner\n",
    "from visualize_data import Visualizer\n",
    "from correlation_analyzer import CorrelationAnalyzer\n",
    "from financial_analyzer import FinancialAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "258090a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCK_FILES_INFO  = {\n",
    "    \"AAPL\": \"../data/raw/AAPL_historical_data.csv\",\n",
    "    \"AMZN\": \"../data/raw/AMZN_historical_data.csv\",\n",
    "    \"GOOG\": \"../data/raw/GOOG_historical_data.csv\",\n",
    "    \"META\": \"../data/raw/META_historical_data.csv\",\n",
    "    \"MSFT\": \"../data/raw/MSFT_historical_data.csv\",\n",
    "    \"NVDA\": \"../data/raw/NVDA_historical_data.csv\",\n",
    "    \"TSLA\": \"../data/raw/TSLA_historical_data.csv\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a9027b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing news data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_path_isfile: path should be string, bytes, os.PathLike or integer, not DataLoader",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading and preparing news data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m news_loader = DataLoader(STOCK_FILES_INFO)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m news_df = \u001b[43mnews_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\Documents\\10\\nova-financial-solutions-week1\\src\\load_data.py:33\u001b[39m, in \u001b[36mDataLoader.load_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(file_path):\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    Load a CSV file into a pandas DataFrame for financial analysis\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m        FileNotFoundError: If the specified file does not exist\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m     df = pd.read_csv(file_path)\n",
      "\u001b[31mTypeError\u001b[39m: _path_isfile: path should be string, bytes, os.PathLike or integer, not DataLoader"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Prepare News Data ---\n",
    "print(\"Loading and preparing news data...\")\n",
    "news_loader = DataLoader(STOCK_FILES_INFO)\n",
    "news_df = news_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85efe2f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'news_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m news_with_sentiment = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnews_df\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m     news_cleaner = DataCleaner(news_df)\n\u001b[32m      4\u001b[39m     cleaned_news_df = news_cleaner.clean_news_data()\n",
      "\u001b[31mNameError\u001b[39m: name 'news_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "news_with_sentiment = None\n",
    "if news_df is not None:\n",
    "    news_cleaner = DataCleaner(news_df)\n",
    "    cleaned_news_df = news_cleaner.clean_news_data()\n",
    "\n",
    "    news_text_analyzer = TextAnalyzer(cleaned_news_df)\n",
    "    news_with_sentiment = news_text_analyzer.perform_sentiment_analysis()\n",
    "    \n",
    "    # Ensure date is normalized to day for merging\n",
    "    news_with_sentiment['date'] = news_with_sentiment['date'].dt.normalize()\n",
    "    print(\"\\nNews data with sentiment prepared.\")\n",
    "    print(news_with_sentiment.head())\n",
    "else:\n",
    "    print(\"Failed to load news data. Cannot proceed with correlation analysis.\")\n",
    "\n",
    "\n",
    "# --- 2. Load and Prepare Stock Data for all tickers ---\n",
    "print(\"\\nLoading and preparing stock data for all tickers...\")\n",
    "stock_loader = DataLoader() # Initialize without news_file_path if only loading stock data\n",
    "all_stock_dfs = stock_loader.load_local_stock_data(STOCK_FILES_INFO)\n",
    "\n",
    "processed_stock_dfs = {}\n",
    "if all_stock_dfs:\n",
    "    for ticker, stock_df in all_stock_dfs.items():\n",
    "        print(f\"\\nProcessing {ticker} stock data for correlation...\")\n",
    "        stock_cleaner = DataCleaner(stock_df)\n",
    "        cleaned_stock_df = stock_cleaner.clean_stock_data()\n",
    "        \n",
    "        # Calculate daily returns\n",
    "        financial_analyzer = FinancialAnalyzer(cleaned_stock_df)\n",
    "        stock_df_with_returns = financial_analyzer.calculate_daily_returns()\n",
    "        \n",
    "        # Ensure stock_df_with_returns index is normalized to day\n",
    "        stock_df_with_returns.index = stock_df_with_returns.index.normalize()\n",
    "        \n",
    "        processed_stock_dfs[ticker] = stock_df_with_returns\n",
    "        print(f\"Finished preparing {ticker} stock data with daily returns.\")\n",
    "else:\n",
    "    print(\"No stock data was loaded. Cannot proceed with correlation analysis.\")\n",
    "\n",
    "\n",
    "# --- 3. Perform Correlation Analysis for all stocks ---\n",
    "if news_with_sentiment is not None and processed_stock_dfs:\n",
    "    print(\"\\nStarting correlation analysis between news sentiment and stock returns for all loaded stocks...\")\n",
    "    correlation_analyzer = CorrelationAnalyzer(news_with_sentiment)\n",
    "    all_correlations = correlation_analyzer.analyze_multiple_stocks(processed_stock_dfs)\n",
    "\n",
    "    print(\"\\n--- Correlation Results ---\")\n",
    "    for ticker, correlation in all_correlations.items():\n",
    "        print(f\"Correlation for {ticker}: {correlation:.4f}\")\n",
    "\n",
    "    # --- 4. Visualize Correlation (example for one stock) ---\n",
    "    print(\"\\nVisualizing correlation (example for the first successfully processed stock)...\")\n",
    "    if all_correlations:\n",
    "        first_ticker = next(iter(all_correlations)) # Get the first ticker\n",
    "        first_stock_df = processed_stock_dfs[first_ticker]\n",
    "\n",
    "        # Re-merge for plotting, as correlation_analyzer.align_and_merge_data is for one stock at a time\n",
    "        temp_correlation_analyzer = CorrelationAnalyzer(news_with_sentiment)\n",
    "        df_for_plot = temp_correlation_analyzer.align_and_merge_data(first_stock_df)\n",
    "\n",
    "        if df_for_plot is not None and not df_for_plot.empty:\n",
    "            visualizer = Visualizer()\n",
    "            visualizer.plot_sentiment_vs_returns_scatter(df_for_plot, title=f\"Avg. Daily Sentiment vs. Daily Returns for {first_ticker}\")\n",
    "            visualizer.plot_correlation_heatmap(df_for_plot, ['Avg_Daily_Sentiment', 'Daily_Return'], title=f\"Correlation Heatmap for {first_ticker}\")\n",
    "        else:\n",
    "            print(\"Could not generate plots for correlation (merged data is empty).\")\n",
    "    else:\n",
    "        print(\"No correlations calculated to plot.\")\n",
    "else:\n",
    "    print(\"Missing news data or stock data to perform correlation analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fd8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d68f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173f7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
